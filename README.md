# PROYECTO FINAL  
**Autora:** Diana C√≥rdova  

---

## üéØ Objetivo  
Mostrar c√≥mo distintas tecnolog√≠as (**KNIME, Airflow, PostgreSQL, MySQL, Elasticsearch, Kibana**) se pueden orquestar para integrar datos sociales y de riesgo en tiempo real, producir indicadores de vulnerabilidad y exposici√≥n, y finalmente generar evidencia √∫til para la gesti√≥n del riesgo de desastres y la toma de decisiones en pol√≠ticas p√∫blicas.

- **Tipo de entorno:** Local  
- **Fuentes de datos iniciales:**  
  - **Reales:** Datos Censo 2022 Ecuador  
  - **Sint√©ticos:** Datos creados a trav√©s de un script en Python (√≠ndice de jefatura de hogar femenina = 1, y cercan√≠a al volc√°n Cotopaxi).  

---

## üõ†Ô∏è Tipo de Pipeline  

**Figura 1: Flujo ELT**  

Herramientas usadas: **KNIME, MySQL (VS Code connector), Apache Airflow (DAGs), Elasticsearch y Kibana**.  

---

## üîπ KNIME  

**Figura 2. Flujo KNIME**  
**Figura 3. Visualizaciones con KNIME**  

- Transformaci√≥n de un CSV de vivienda para evaluar la vulnerabilidad frente al Cotopaxi.  
- Depuraci√≥n de columnas irrelevantes, filtrado por provincia Pichincha, creaci√≥n de RowID limpio.  
- Imputaci√≥n de valores faltantes y construcci√≥n de indicadores clave como **d√©ficit habitacional** y un **puntaje socioecon√≥mico de vulnerabilidad**.  
- Integraci√≥n de datos auxiliares desde **MySQL**, normalizaci√≥n de identificadores, creaci√≥n de variable de exposici√≥n.  
- C√°lculo de un **puntaje final de vulnerabilidad (0‚Äì10)** con reglas y f√≥rmulas.  
- Validaci√≥n visual de duplicados/inconsistencias, exportaci√≥n final a **base de datos** y **CSV**.  

---

## üìã Retos y Soluciones

| **Reto** | **Soluci√≥n** |
|----------|--------------|
| Conexi√≥n a MySQL desde terminal (Access denied, cambios no visibles) | Revis√© credenciales, cre√© usuario con permisos, activ√© Autocommit / DB Transaction End en KNIME. |
| Creaci√≥n de tablas sint√©ticas en MySQL (135,068 filas, errores DECIMAL, out of range) | Us√© `DROP TABLE IF EXISTS`, ajust√© MD5 + CONV, aument√© precisi√≥n de columnas (DECIMAL(7,2)). |
| Formato de identificadores (Row0 vs ROW-000001) | Reemplac√© f√≥rmulas en SQL y us√© String Manipulation + RowID en KNIME para uniformar joins. |
| Definir escalas de puntaje de vulnerabilidad | Constru√≠ columnas derivadas (Math Formula, Rule Engine) y escal√© √≠ndice final 0‚Äì10. |
| Validaci√≥n visual y duplicados | Histogramas, scatter plots (JavaScript Views), GroupBy y consultas SQL para confirmar las 135,068 filas. |

---

## üêç Generaci√≥n de Datos Sint√©ticos en Python  

**Script:** `seismic_events_nrt.py`  

- Simula eventos s√≠smicos con atributos f√≠sicos (**magnitud, profundidad, proximidad al volc√°n**).  
- Emisi√≥n en:  
  - **Archivos NDJSON** (batch para Airflow).  
  - **Directo a Elasticsearch** (streaming).  
- Campos: `station_id, ts_event, magnitude_ml, depth_km, proximidad_volcan_km`.  

| **Reto** | **Soluci√≥n** |
|----------|--------------|
| `SyntaxError` en contador total | Correg√≠ a `total += 1`. |
| √çndice no creado en ES (404) | Ajust√© condici√≥n `if MODE in ("es","both")`. |
| Duplicaci√≥n de datos en modo both | Decid√≠ entre `file` o `es` seg√∫n escenario. |
| Conexi√≥n rechazada a ES | Valid√© que contenedor `elasticsearch` estuviera activo en `localhost:9200`. |

---

## üì¶ Ingesta y Almacenamiento en Elasticsearch  

- Indexaci√≥n de datos batch (censo_batch) y simulados (seismic_rt-*).  
- Definici√≥n de **mappings**:  
  - `magnitude_ml, depth_km, proximidad_volcan_km` ‚Üí float  
  - `vulnerabilidad_score` ‚Üí integer  
  - `location` ‚Üí geo_point  
  - `ts_event, updated_at` ‚Üí date  

**Con DAG en Airflow:**  
- Exportaci√≥n autom√°tica desde batch + near-real-time hacia ES.  
- Resoluci√≥n de problemas de tipado mediante casting.  
- Normalizaci√≥n de nulos y fechas ISO 8601.  
- Uso de `helpers.bulk` con lotes peque√±os y reintentos.  
- Definici√≥n de `geo_point` para visualizaciones en Kibana.  

| **Reto** | **Soluci√≥n** |
|----------|--------------|
| Duplicados tras join | Cambi√© Joiner en KNIME a `modifier=left`. |
| Campos num√©ricos como texto | Casting expl√≠cito en DAG. |
| Dynamic mapping mal interpretado | Defin√≠ mappings antes del bulk. |
| Kibana no reconoc√≠a fechas | Export√© con `.isoformat()`. |
| Payload demasiado grande | Us√© `helpers.bulk` con lotes m√°s peque√±os. |
| Connection refused | A√±ad√≠ dependencia de salud en Compose + validaci√≥n con `/_count`. |
| Visualizaciones geoespaciales bloqueadas | Defin√≠ `location` como geo_point. |

---

## üìä Visualizaci√≥n en Kibana  

- **Index patterns:** `censo_batch*` y `seismic*`.  
- Visualizaciones:  
  - Histogramas de magnitud por estaci√≥n.  
  - Mapas de calor de vulnerabilidad por provincia y zona de lahar.  
  - Scatter plot proximidad‚Äìvulnerabilidad.  
  - Mapas de eventos s√≠smicos geolocalizados.  

**Figura 5. Visualizaciones batch y near-real-time.**

---

## ‚úÖ Conclusiones  

Este pipeline integr√≥ **fuentes de datos heterog√©neas** (censo en CSV + datos sint√©ticos en MySQL), usando KNIME como base.  
Con **Apache Airflow** orquest√© procesos **batch y near-real-time**, estructurando un flujo reproducible.  

Los **datos sint√©ticos** representaron fen√≥menos f√≠sicos y sociales, y fueron indexados en **Elasticsearch**, resolviendo problemas de tipado y consistencia.  

Finalmente, constru√≠ **dashboards interactivos en Kibana** para visualizar relaciones entre actividad s√≠smica y vulnerabilidad socioecon√≥mica.  

üëâ Este proyecto constituye un **pipeline end-to-end** que demuestra capacidades en:  
- **ETL y orquestaci√≥n de flujos**.  
- **Simulaci√≥n de datos realistas**.  
- **Indexaci√≥n eficiente en motores de b√∫squeda**.  
- **Visualizaci√≥n en tiempo real**.  
